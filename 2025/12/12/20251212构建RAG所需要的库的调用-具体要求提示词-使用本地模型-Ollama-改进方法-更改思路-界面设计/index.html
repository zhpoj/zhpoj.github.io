<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>20251212构建RAG所需要的库的调用+具体要求提示词+使用本地模型+Ollama+改进方法 +更改思路+界面设计 | 张红坡的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="1.所需要的库的调用&#96;&#96;try:&#96;   from langchain_community.document_loaders import PyPDFLoader   from langchain_text_splitters import CharacterTextSplitter   from langchain_community.vectorstores impo">
<meta property="og:type" content="article">
<meta property="og:title" content="20251212构建RAG所需要的库的调用+具体要求提示词+使用本地模型+Ollama+改进方法 +更改思路+界面设计">
<meta property="og:url" content="http://zhpoj.github.io/2025/12/12/20251212%E6%9E%84%E5%BB%BARAG%E6%89%80%E9%9C%80%E8%A6%81%E7%9A%84%E5%BA%93%E7%9A%84%E8%B0%83%E7%94%A8-%E5%85%B7%E4%BD%93%E8%A6%81%E6%B1%82%E6%8F%90%E7%A4%BA%E8%AF%8D-%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%9E%8B-Ollama-%E6%94%B9%E8%BF%9B%E6%96%B9%E6%B3%95-%E6%9B%B4%E6%94%B9%E6%80%9D%E8%B7%AF-%E7%95%8C%E9%9D%A2%E8%AE%BE%E8%AE%A1/index.html">
<meta property="og:site_name" content="张红坡的博客">
<meta property="og:description" content="1.所需要的库的调用&#96;&#96;try:&#96;   from langchain_community.document_loaders import PyPDFLoader   from langchain_text_splitters import CharacterTextSplitter   from langchain_community.vectorstores impo">
<meta property="og:locale">
<meta property="article:published_time" content="2025-12-12T14:04:48.000Z">
<meta property="article:modified_time" content="2025-12-12T14:05:08.429Z">
<meta property="article:author" content="张红坡">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="张红坡的博客" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">张红坡的博客</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Buscar"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Buscar"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://zhpoj.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-20251212构建RAG所需要的库的调用-具体要求提示词-使用本地模型-Ollama-改进方法-更改思路-界面设计" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/12/12/20251212%E6%9E%84%E5%BB%BARAG%E6%89%80%E9%9C%80%E8%A6%81%E7%9A%84%E5%BA%93%E7%9A%84%E8%B0%83%E7%94%A8-%E5%85%B7%E4%BD%93%E8%A6%81%E6%B1%82%E6%8F%90%E7%A4%BA%E8%AF%8D-%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%9E%8B-Ollama-%E6%94%B9%E8%BF%9B%E6%96%B9%E6%B3%95-%E6%9B%B4%E6%94%B9%E6%80%9D%E8%B7%AF-%E7%95%8C%E9%9D%A2%E8%AE%BE%E8%AE%A1/" class="article-date">
  <time class="dt-published" datetime="2025-12-12T14:04:48.000Z" itemprop="datePublished">2025-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      20251212构建RAG所需要的库的调用+具体要求提示词+使用本地模型+Ollama+改进方法 +更改思路+界面设计
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <span id="more"></span>

<h5 id="1-所需要的库的调用"><a href="#1-所需要的库的调用" class="headerlink" title="1.所需要的库的调用"></a>1.所需要的库的调用</h5><p>&#96;&#96;try:&#96;</p>
<p>  <code>from langchain_community.document_loaders import PyPDFLoader</code></p>
<p>  <code>from langchain_text_splitters import CharacterTextSplitter</code></p>
<p>  <code>from langchain_community.vectorstores import FAISS</code></p>
<p>  <code>from langchain_huggingface import HuggingFaceEmbeddings</code></p>
<p>  <code>\# 尝试导入新的 langchain-ollama 库，如果不存在则回退到旧版</code></p>
<p>  <code>try:</code></p>
<p>​    <code>from langchain_ollama import OllamaLLM as Ollama</code></p>
<p>  <code>except ImportError:</code></p>
<p>​    <code>from langchain_community.llms import Ollama</code></p>
<p>  <code>from langchain_core.prompts import PromptTemplate</code></p>
<p>  <code>from langchain_core.runnables import RunnablePassthrough</code></p>
<p>  <code>from langchain_core.output_parsers import StrOutputParser</code></p>
<h5 id="2-请使用Python和LangChain框架编写一个RAG系统的代码。具体要求如下："><a href="#2-请使用Python和LangChain框架编写一个RAG系统的代码。具体要求如下：" class="headerlink" title="2.请使用Python和LangChain框架编写一个RAG系统的代码。具体要求如下："></a>2.请使用Python和LangChain框架编写一个RAG系统的代码。具体要求如下：</h5><ol>
<li>文档加载：使用LangChain的PyPDFLoader加载指定路径的PDF文件。</li>
<li>文本分割：使用CharacterTextSplitter，设置块大小为500，重叠为50。</li>
<li>向量存储：使用本地部署的向量模型（模型为all-MiniLM-L6-v2）和Faiss向量数据库。</li>
<li>检索器：从Faiss中创建检索器，检索最相关的5个文档块。</li>
<li>生成：使用本地模型（模型为deepseek-r1:1.5b）和提示词模板，将检索到的文档块和用户问题结合生成答案。<br>6.使用tk组件作为前端人机交互页面，并自动增加人机交互功能。<br>7.我用的python是3.13，请使用最新的langchain库。<br>8.代码仅存在于测试1.py中。</li>
</ol>
<p>提示词模板为：<br> “基于以下上下文，回答用户的问题。如果上下文不包含答案，请根据你的知识回答，但请注明答案并非来自上下文。</p>
<p> 上下文：{context}</p>
<p> 问题：{question}</p>
<p> 答案：”</p>
<p>请给出完整的代码，并添加必要的注释。</p>
<h5 id="3-all-MiniLM-L6-v2怎么使用本地模型？"><a href="#3-all-MiniLM-L6-v2怎么使用本地模型？" class="headerlink" title="3.all-MiniLM-L6-v2怎么使用本地模型？"></a>3.all-MiniLM-L6-v2怎么使用本地模型？</h5><ol>
<li>Hugging Face (例如 <code>sentence-transformers/all-MiniLM-L6-v2</code>) 下载所有文件到一个文件夹中（例如命名为 <code>all-MiniLM-L6-v2</code>）。</li>
<li><strong>指定路径</strong>：在代码中将模型名称替换为该文件夹的路径。</li>
</ol>
<p>要使用本地下载好的 <code>all-MiniLM-L6-v2</code> 模型，您只需要将 <code>HuggingFaceEmbeddings</code> 中的 <code>model_name</code> 参数指向您存放模型文件的<strong>本地文件夹路径</strong>即可。</p>
<p><code>self.embeddings = HuggingFaceEmbeddings(model_name=r&quot;D:\Models\all-MiniLM-L6-v2&quot;)</code></p>
<p>3.我修改后的代码会自动检查当前目录下是否有 <code>all-MiniLM-L6-v2</code> 文件夹：</p>
<ul>
<li>如果<strong>有</strong>：它会直接加载本地路径，无需联网。</li>
<li>如果<strong>没有</strong>：它会尝试从 Hugging Face Hub 自动下载（需要联网，下载后会缓存）</li>
</ul>
<h5 id="4-D-python-RAG313-E-PythonProject-RAG-TEST-D-python-RAG313-python-exe-e-PythonProject-RAG-TEST-测试1-py"><a href="#4-D-python-RAG313-E-PythonProject-RAG-TEST-D-python-RAG313-python-exe-e-PythonProject-RAG-TEST-测试1-py" class="headerlink" title="4.(D:\python\RAG313) E:\PythonProject\RAG_TEST&gt;D:&#x2F;python&#x2F;RAG313&#x2F;python.exe e:&#x2F;PythonProject&#x2F;RAG_TEST&#x2F;测试1.py"></a>4.(D:\python\RAG313) E:\PythonProject\RAG_TEST&gt;D:&#x2F;python&#x2F;RAG313&#x2F;python.exe e:&#x2F;PythonProject&#x2F;RAG_TEST&#x2F;测试1.py</h5><p>正在初始化 Embeddings (all-MiniLM-L6-v2)…<br>正在初始化 LLM (deepseek-r1:1.5b)…<br>LLM 初始化失败: ‘module’ object is not callable<br>这样怎么解决？</p>
<p>这个错误是因为导入 <code>Ollama</code> 的方式不正确，导致代码把 <code>ollama</code> 模块当成了类来调用。</p>
<h5 id="5-e-PythonProject-RAG-TEST-测试1-py"><a href="#5-e-PythonProject-RAG-TEST-测试1-py" class="headerlink" title="5.e:&#x2F;PythonProject&#x2F;RAG_TEST&#x2F;测试1.py"></a>5.e:&#x2F;PythonProject&#x2F;RAG_TEST&#x2F;测试1.py</h5><p>正在初始化 Embeddings (all-MiniLM-L6-v2)…<br>正在初始化 LLM (deepseek-r1:1.5b)…<br>e:\PythonProject\RAG_TEST\测试1.py:44: LangChainDeprecationWarning: The class <code>Ollama</code> was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the <code>langchain-ollama package and should be used instead. To use it run </code>pip install -U <code>langchain-ollama</code> and import as <code>from </code>langchain_ollama import OllamaLLM&#96;&#96;.<br>  self.llm &#x3D; Ollama(model&#x3D;”deepseek-r1:1.5b”)<br>这是为什么？</p>
<p>这是因为 LangChain 在 0.3.x 版本中进行了架构调整，将各个模型的集成（如 Ollama、OpenAI 等）拆分到了独立的包中，以方便管理和维护。</p>
<p>您当前使用的 <code>langchain_community.llms.Ollama</code> 类已被标记为“弃用”（Deprecated），虽然目前还能用，但在未来的 1.0.0 版本中会被移除。官方建议使用新的 <code>langchain-ollama</code> 包中的 <code>OllamaLLM</code> 类。</p>
<p><strong>安装新包</strong>：在终端中运行以下命令安装 <code>langchain-ollama</code>：</p>
<p><code>pip install langchain-ollama</code></p>
<h5 id="6-运行时出现错误：生成答案时出错-WinError-10049-在其上下文中，该请求的地址无效。"><a href="#6-运行时出现错误：生成答案时出错-WinError-10049-在其上下文中，该请求的地址无效。" class="headerlink" title="6.运行时出现错误：生成答案时出错: [WinError 10049] 在其上下文中，该请求的地址无效。"></a>6.运行时出现错误：生成答案时出错: [WinError 10049] 在其上下文中，该请求的地址无效。</h5><ol>
<li><p><strong>确保 Ollama 正在运行</strong>：<br>请检查您的电脑右下角是否有 Ollama 的图标，或者在终端中运行 <code>ollama serve</code> 确保服务已启动。</p>
</li>
<li><p><strong>强制使用 IPv4 地址</strong>：<br>我已经修改了代码，显式指定了 <code>base_url=&quot;http://127.0.0.1:11434&quot;</code>。在 Windows 上，有时默认的 <code>localhost</code> 会被解析为 IPv6 地址，导致连接失败，使用 <code>127.0.0.1</code> 通常能解决这个问题</p>
</li>
<li><p># 显式指定 base_url 为 127.0.0.1 以避免 Windows 下 localhost 解析导致的 WinError 10049</p>
<p>​      <code>self.llm = Ollama(model=&quot;deepseek-r1:1.5b&quot;, base_url=&quot;http://127.0.0.1:11434&quot;)</code></p>
<p>​    <code>except Exception as e:</code></p>
</li>
</ol>
<h5 id="7-如何修改成，将文本向量化之后，将向量数据库保存到本地，然后关闭程序后，下次不需要再导入文件，而是直接加载向量数据库呢？"><a href="#7-如何修改成，将文本向量化之后，将向量数据库保存到本地，然后关闭程序后，下次不需要再导入文件，而是直接加载向量数据库呢？" class="headerlink" title="7.如何修改成，将文本向量化之后，将向量数据库保存到本地，然后关闭程序后，下次不需要再导入文件，而是直接加载向量数据库呢？"></a>7.如何修改成，将文本向量化之后，将向量数据库保存到本地，然后关闭程序后，下次不需要再导入文件，而是直接加载向量数据库呢？</h5><p><strong>修改内容：</strong></p>
<ol>
<li><strong>自动保存</strong>：<br>在 <code>load_and_process_pdf</code> 方法中，当您加载并处理完一个新的 PDF 文件后，程序会自动将生成的向量数据库保存到当前目录下的 <code>faiss_index</code> 文件夹中。</li>
<li><strong>自动加载</strong>：<br>在程序启动时（<code>RAGSystem</code> 初始化阶段），它会自动检查是否存在 <code>faiss_index</code> 文件夹。<ul>
<li>如果存在，它会直接加载这个本地数据库，并初始化检索器和问答链。</li>
<li>界面上的状态栏会显示“已加载本地向量数据库”。</li>
</ul>
</li>
<li><strong>使用流程</strong>：<ul>
<li><strong>第一次运行</strong>：选择 PDF 文件 -&gt; 程序处理 -&gt; <strong>自动保存到本地</strong> -&gt; 可以提问。</li>
<li><strong>第二次运行</strong>：程序启动 -&gt; <strong>自动加载本地数据库</strong> -&gt; 无需选择文件，直接提问即可。</li>
</ul>
</li>
</ol>
<h2 id="请问这个代码还可以增加哪些功能？还可以进行哪些改进？请给个修改的方向意见建议？"><a href="#请问这个代码还可以增加哪些功能？还可以进行哪些改进？请给个修改的方向意见建议？" class="headerlink" title="*请问这个代码还可以增加哪些功能？还可以进行哪些改进？请给个修改的方向意见建议？"></a>*请问这个代码还可以增加哪些功能？还可以进行哪些改进？请给个修改的方向意见建议？</h2><h5 id="1-已经具备了-RAG-的核心骨架（加载、切分、索引、检索、生成、持久化），但在实际应用和用户体验上还有很大的提升空间。"><a href="#1-已经具备了-RAG-的核心骨架（加载、切分、索引、检索、生成、持久化），但在实际应用和用户体验上还有很大的提升空间。" class="headerlink" title="1.已经具备了 RAG 的核心骨架（加载、切分、索引、检索、生成、持久化），但在实际应用和用户体验上还有很大的提升空间。"></a>1.已经具备了 RAG 的核心骨架（加载、切分、索引、检索、生成、持久化），但在实际应用和用户体验上还有很大的提升空间。</h5><p>知识库管理：允许用户创建、切换、重命名不同的知识库（例如“技术文档库”、“合同库”），或者提供一个“清空&#x2F;重建知识库”的按钮。</p>
<p>支持更多文件格式：现状: 仅支持 PDF。 增加对 <code>.txt</code>, <code>.docx</code> (使用 <code>Docx2txtLoader</code>), <code>.md</code>, <code>.csv</code> 等格式的支持。可以根据文件后缀名自动选择加载器。</p>
<p>用户体验输出：利用 LangChain 的流式回调 (CallbackHandler) 或 <code>.stream()</code> 方法，配合 Tkinter 的动态刷新，实现像 ChatGPT 那样“打字机”式的逐字显示效果。</p>
<p>设置面板：现状: 模型路径、Chunk Size、检索数量 k 都是硬编码的。建议: 增加一个“设置”弹窗，允许用户在界面上修改：</p>
<ul>
<li>选择 Ollama 模型 (deepseek, llama3, qwen 等)。</li>
<li>调整检索文档数量 (Top-K)。</li>
<li>调整温度 (Temperature，控制回答的随机性)。</li>
</ul>
<h3 id="修改"><a href="#修改" class="headerlink" title="*修改"></a>*修改</h3><h5 id="改用-RecursiveCharacterTextSplitter。它会尝试按段落、句子、单词的顺序进行切分，能更好地保留语义完整性。"><a href="#改用-RecursiveCharacterTextSplitter。它会尝试按段落、句子、单词的顺序进行切分，能更好地保留语义完整性。" class="headerlink" title="改用 RecursiveCharacterTextSplitter。它会尝试按段落、句子、单词的顺序进行切分，能更好地保留语义完整性。"></a>改用 RecursiveCharacterTextSplitter。它会尝试按段落、句子、单词的顺序进行切分，能更好地保留语义完整性。</h5><ol>
<li><strong>导入变更</strong>：<br>将 <code>from langchain_text_splitters import CharacterTextSplitter</code> 修改为 <code>from langchain_text_splitters import RecursiveCharacterTextSplitter</code>。</li>
</ol>
<p>  2.在 <code>load_and_process_pdf</code> 方法中，使用了新的分割器配置：</p>
<p><code>text_splitter = RecursiveCharacterTextSplitter(</code><br>    <code>chunk_size=500,</code><br>    <code>chunk_overlap=50,</code><br>    <code>separators=[&quot;\n\n&quot;, &quot;\n&quot;, &quot;。&quot;, &quot;！&quot;, &quot;？&quot;, &quot; &quot;, &quot;&quot;], # 优先级：双换行 &gt; 单换行 &gt; 中文句号 &gt; 感叹号 &gt; 问号 &gt; 空格 &gt; 字符</code><br>    <code>length_function=len,</code><br>    <code>is_separator_regex=False</code><br><code>)</code></p>
<p>加载 PDF 时，系统会优先尝试在段落和句子结束的地方进行切分，而不是在句子中间硬生生切断。这将显著提高检索到的文本块的语义完整性，从而让 AI 生成的回答更加准确和连贯。</p>
<h5 id="增加一个“设置”弹窗，允许用户在界面上修改；调整温度-Temperature，控制回答的随机性"><a href="#增加一个“设置”弹窗，允许用户在界面上修改；调整温度-Temperature，控制回答的随机性" class="headerlink" title="增加一个“设置”弹窗，允许用户在界面上修改；调整温度 (Temperature，控制回答的随机性)"></a>增加一个“设置”弹窗，允许用户在界面上修改；调整温度 (Temperature，控制回答的随机性)</h5><ol>
<li>**后端 (<code>RAGSystem</code>)**：<ul>
<li>增加了 <code>self.temperature</code> 属性，默认值为 0.7。</li>
<li>将 LLM 的初始化逻辑提取到了 <code>init_llm</code> 方法中，并在初始化 <code>Ollama</code> 时传入了 <code>temperature</code> 参数。</li>
<li>增加了 <code>update_settings</code> 方法，用于接收新的温度值并重新初始化 LLM 和 Chain。</li>
</ul>
</li>
<li>**前端 (<code>RAGGUI</code>)**：<ul>
<li>在顶部工具栏增加了一个“设置”按钮。</li>
<li>实现了 <code>open_settings</code> 方法，弹出一个新的窗口 (<code>Toplevel</code>)。</li>
<li>在设置窗口中，用户可以输入 0.0 到 1.0 之间的数字。</li>
<li>点击“保存”后，会调用后端的 <code>update_settings</code> 方法更新模型参数。</li>
</ul>
</li>
</ol>
<ul>
<li><p>Temperature (温度)</p>
<p>：控制 AI 回答的随机性。</p>
<ul>
<li>**接近 0 (如 0.1)**：回答非常严谨、确定，适合事实性问答。</li>
<li>**接近 1 (如 0.9)**：回答更具创造性、随机性，适合创意写作。</li>
</ul>
</li>
</ul>
<h5 id="给我增加一个清理向量库的功能，我的意思是重置"><a href="#给我增加一个清理向量库的功能，我的意思是重置" class="headerlink" title="给我增加一个清理向量库的功能，我的意思是重置"></a>给我增加一个清理向量库的功能，我的意思是重置</h5><ol>
<li>**后端 (<code>RAGSystem</code>)**：<ul>
<li>增加了 <code>clear_vector_store</code> 方法。</li>
<li>该方法会：<ol>
<li>将内存中的 <code>vector_store</code>, <code>retriever</code>, <code>chain</code> 对象置为 <code>None</code>。</li>
<li>使用 <code>shutil.rmtree</code> 彻底删除本地的 [faiss_index](vscode-file:&#x2F;&#x2F;vscode-app&#x2F;d:&#x2F;Users&#x2F;poe&#x2F;AppData&#x2F;Local&#x2F;Programs&#x2F;Microsoft VS Code&#x2F;resources&#x2F;app&#x2F;out&#x2F;vs&#x2F;code&#x2F;electron-browser&#x2F;workbench&#x2F;workbench.html) 文件夹。</li>
</ol>
</li>
</ul>
</li>
<li>**前端 (<code>RAGGUI</code>)**：<ul>
<li>在设置窗口中增加了一个“清空向量库”按钮。</li>
<li>点击按钮时会弹出确认对话框。</li>
<li>确认后调用后端的清理方法，并更新界面状态（将文件标签重置为“未选择文件”）。</li>
</ul>
</li>
</ol>
<h5 id="请将我这个页面给我完善美化一下，给出美化建议，并给我优化程序的建议。"><a href="#请将我这个页面给我完善美化一下，给出美化建议，并给我优化程序的建议。" class="headerlink" title="请将我这个页面给我完善美化一下，给出美化建议，并给我优化程序的建议。"></a>请将我这个页面给我完善美化一下，给出美化建议，并给我优化程序的建议。</h5><ol>
<li><strong>消息气泡样式</strong>：利用 <code>tag_config</code> 让用户的消息<strong>右对齐显示为蓝色</strong>，AI 的消息<strong>左对齐显示为黑色</strong>，系统消息<strong>居中显示为灰色</strong>。</li>
<li><strong>状态栏</strong>：在底部增加一个状态栏，实时显示“正在思考…”、“就绪”等状态，比弹窗更优雅。</li>
</ol>
<p>改进内容：</p>
<ol>
<li><p><strong>整体风格</strong>：</p>
<ul>
<li>使用了 <code>Microsoft YaHei</code> 字体，看起来更现代。</li>
<li>增加了组件的 Padding（间距），界面不再拥挤。</li>
<li>使用了 <code>LabelFrame</code> 将不同功能区（文档加载、对话记录、输入区）清晰地分隔开。</li>
</ul>
<p>2.<strong>聊天窗口优化</strong>：</p>
</li>
</ol>
<ul>
<li><p><strong>背景色</strong>：改为浅灰色 (<code>#F5F5F5</code>)，更加护眼。</p>
</li>
<li><p>消息区分</p>
<p>：</p>
<ul>
<li><strong>用户消息</strong>：蓝色字体，<strong>右对齐</strong>，模拟主流聊天软件的体验。</li>
<li><strong>AI 消息</strong>：深灰色字体，左对齐。</li>
<li><strong>系统消息</strong>：灰色字体，居中显示，用于提示文件加载状态等。</li>
<li><strong>引用来源</strong>：绿色字体，清晰区分正文和参考文档。</li>
</ul>
</li>
</ul>
<h2 id="可更改的思路"><a href="#可更改的思路" class="headerlink" title="可更改的思路"></a>可更改的思路</h2><p>1.代码结构分离：</p>
<p>目前所有代码都在一个文件中。</p>
<ul>
<li><em>建议</em>：将 <code>RAGSystem</code> 类（后端逻辑）和 <code>RAGGUI</code> 类（前端界面）拆分到两个不同的 <code>.py</code> 文件中（例如 <code>backend.py</code> 和 <code>main.py</code>），便于维护和扩展。</li>
</ul>
<p>2.多轮对话记忆</p>
<p>建议：引入 LangChain 的 <code>ConversationBufferMemory</code>，将历史对话传给 LLM，这样您就可以说“请详细解释一下第二点”，AI 就能理解上下文。</p>
<p>3.使用现代的UI库</p>
<p>目前的 Tkinter 样式虽然经过调整，但仍然比较传统。建议尝试 <strong><code>ttkbootstrap</code></strong> 或 <strong><code>CustomTkinter</code></strong> 库。它们只需几行代码就能让界面变成现代化的扁平风格（Flat Design）或暗黑模式（Dark Mode）。</p>
<h4 id="界面设计思路"><a href="#界面设计思路" class="headerlink" title="*界面设计思路"></a>*界面设计思路</h4><h6 id="用-ttkbootstrap-或-CustomTkinter-库，让界面变成现代化的风格"><a href="#用-ttkbootstrap-或-CustomTkinter-库，让界面变成现代化的风格" class="headerlink" title="用 ttkbootstrap 或 CustomTkinter 库，让界面变成现代化的风格"></a>用 ttkbootstrap 或 CustomTkinter 库，让界面变成现代化的风格</h6><p><strong>现代化 UI 风格</strong>：</p>
<ul>
<li>使用了 <code>litera</code> 主题（清爽的扁平化风格）。</li>
<li>所有组件（按钮、输入框、标签）都使用了 Bootstrap 风格的样式（<code>primary</code>, <code>success</code>, <code>info</code>, <code>danger</code> 等）。</li>
<li>界面更加简洁、大气，告别了原生 Tkinter 的“复古感”</li>
</ul>
<ol>
<li><strong>交互体验提升</strong>：<ul>
<li><strong>设置窗口</strong>：将温度设置改为**滑动条 (Scale)**，拖动即可调整，更加直观。</li>
<li><strong>状态反馈</strong>：按钮和标签使用了语义化的颜色（例如：加载成功是绿色 <code>success</code>，清空是红色 <code>danger</code>，处理中是黄色 <code>warning</code>）。</li>
<li><strong>布局优化</strong>：增加了更多的留白（Padding），使用了卡片式布局（Labelframe），层次感更强。</li>
</ul>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://zhpoj.github.io/2025/12/12/20251212%E6%9E%84%E5%BB%BARAG%E6%89%80%E9%9C%80%E8%A6%81%E7%9A%84%E5%BA%93%E7%9A%84%E8%B0%83%E7%94%A8-%E5%85%B7%E4%BD%93%E8%A6%81%E6%B1%82%E6%8F%90%E7%A4%BA%E8%AF%8D-%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%9E%8B-Ollama-%E6%94%B9%E8%BF%9B%E6%96%B9%E6%B3%95-%E6%9B%B4%E6%94%B9%E6%80%9D%E8%B7%AF-%E7%95%8C%E9%9D%A2%E8%AE%BE%E8%AE%A1/" data-id="cmkav97yy0003is2m2uw997py" data-title="20251212构建RAG所需要的库的调用+具体要求提示词+使用本地模型+Ollama+改进方法 +更改思路+界面设计" class="article-share-link"><span class="fa fa-share">Compartir</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2025/12/12/20251212%E5%9B%BE%E7%89%87%E6%98%BE%E7%A4%BA%E6%8F%92%E4%BB%B6%E5%91%BD%E4%BB%A4%E4%B8%8B%E8%BD%BD%E5%91%BD%E4%BB%A4/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Nuevo</strong>
      <div class="article-nav-title">
        
          20251212图片显示插件命令下载命令
        
      </div>
    </a>
  
  
    <a href="/2025/12/08/%E2%80%9C20250425%E7%BB%84%E4%BC%9A%E5%BC%A0%E7%BA%A2%E5%9D%A1%E2%80%9D/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Viejo</strong>
      <div class="article-nav-title">“20250425组会张红坡”</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archivos</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/12/">December 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/11/">November 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/09/">September 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Posts recientes</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/12/12/20251212%E5%9B%BE%E7%89%87%E6%98%BE%E7%A4%BA%E6%8F%92%E4%BB%B6%E5%91%BD%E4%BB%A4%E4%B8%8B%E8%BD%BD%E5%91%BD%E4%BB%A4/">20251212图片显示插件命令下载命令</a>
          </li>
        
          <li>
            <a href="/2025/12/12/20251212%E6%9E%84%E5%BB%BARAG%E6%89%80%E9%9C%80%E8%A6%81%E7%9A%84%E5%BA%93%E7%9A%84%E8%B0%83%E7%94%A8-%E5%85%B7%E4%BD%93%E8%A6%81%E6%B1%82%E6%8F%90%E7%A4%BA%E8%AF%8D-%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%9E%8B-Ollama-%E6%94%B9%E8%BF%9B%E6%96%B9%E6%B3%95-%E6%9B%B4%E6%94%B9%E6%80%9D%E8%B7%AF-%E7%95%8C%E9%9D%A2%E8%AE%BE%E8%AE%A1/">20251212构建RAG所需要的库的调用+具体要求提示词+使用本地模型+Ollama+改进方法 +更改思路+界面设计</a>
          </li>
        
          <li>
            <a href="/2025/12/08/%E2%80%9C20250425%E7%BB%84%E4%BC%9A%E5%BC%A0%E7%BA%A2%E5%9D%A1%E2%80%9D/">“20250425组会张红坡”</a>
          </li>
        
          <li>
            <a href="/2025/12/03/20251202%E5%A4%A7%E8%AE%BA%E6%96%87%E5%87%86%E5%A4%87%E6%97%B6%E9%97%B4-%E4%B8%93%E5%88%A9%E4%B9%A6%E5%86%99-%E5%BC%80%E9%A2%98%E6%8A%A5%E5%91%8A%E6%8F%90%E4%BA%A4-%E5%85%9A%E8%AF%BE/">20251202大论文准备时间+专利书写+开题报告提交+党课</a>
          </li>
        
          <li>
            <a href="/2025/12/01/hexo%E5%9B%BE%E7%89%87%E6%88%90%E5%8A%9F%E4%B8%8A%E4%BC%A0/">hexo图片成功上传</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2026 张红坡<br>
      Construido por <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>